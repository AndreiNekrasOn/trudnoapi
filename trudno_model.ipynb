{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TruDno5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaE_8L-qOZY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q catboost\n",
        "!pip install -q geopy\n",
        "!pip install -q eli5\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from geopy.geocoders import Nominatim\n",
        "from geopy.extra.rate_limiter import RateLimiter\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from catboost import CatBoostClassifier, CatBoostRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import os\n",
        "\n",
        "import scipy\n",
        "import eli5\n",
        "plt.rcParams['figure.figsize'] = [12, 6]\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_S_1ZKjGH_T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82520e72-9bd5-4935-9dc5-b3152b3c407e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C5wM2IqOUdi",
        "colab_type": "text"
      },
      "source": [
        "# Обработка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gfz9OqJsGcFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(name, path='/content/drive/My Drive/Hacaton/Data/'):\n",
        "  if os.path.exists(path+name):\n",
        "    return pd.read_csv(path + name, low_memory=False, sep=';', index_col=0)\n",
        "  print(path+name)\n",
        "  raise FileNotFoundError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaaK4r2FJXrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_dataset(df, name, path='/content/drive/My Drive/Hacaton/Data/'):\n",
        "  df.to_csv(path + name, sep=';')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB7EdQsHHqij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_date(df, name_column_date):\n",
        "    series_date_datetime = pd.to_datetime(df[name_column_date])\n",
        "    df.loc[:, 'year'] = series_date_datetime.apply(lambda x: x.year)\n",
        "    df.loc[:, 'month'] = series_date_datetime.apply(lambda x: x.month)\n",
        "    df.loc[:, 'day'] = series_date_datetime.apply(lambda x: x.day)\n",
        "    df.loc[:, 'hour'] = series_date_datetime.apply(lambda x: x.hour)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCqcpaNRHUVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_data(df):\n",
        "  # drop useless columns\n",
        "  data_vacs_clean = df.drop(columns=['id', 'name', 'area.name', 'company_link', 'salary_currency',\n",
        "                                           'employment.name', 'schedule.name', 'experience.name', \n",
        "                                           'description','type'])\n",
        "  parse_date(data_vacs_clean, 'publication_date')\n",
        "  data_vacs_clean = data_vacs_clean.drop(columns=['publication_date'])\n",
        "  # simplify key_skills format\n",
        "  data_vacs_clean.loc[:, \"key_skills\"] = (data_vacs_clean.key_skills.astype(str) != \"nan\").astype(int)\n",
        "  return data_vacs_clean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDBOM7UGIDTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def spec_modif(elem):\n",
        "  lst = elem.split()\n",
        "  for i in range(len(lst)):\n",
        "    lst[i] = int(lst[i].split('.')[0])\n",
        "  \n",
        "  first_mode = max(set(lst), key=lst.count)\n",
        "  second_mode = 0\n",
        "\n",
        "  if len(set(lst)) >= 2:\n",
        "    lst = list(filter(lambda a: a != first_mode, lst))\n",
        "    second_mode = max(set(lst), key=lst.count)\n",
        "\n",
        "  return first_mode, second_mode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVjyRT0nISAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# или выделяем все специализации\n",
        "def spec_modif_all(df):\n",
        "  def _process_specs(elem):\n",
        "    specs = set()\n",
        "    for spec in elem.split():\n",
        "      specs.add(int(spec.split('.')[0]))\n",
        "    return specs\n",
        "  indexes = df.index\n",
        "  df.loc[:, \"specializations\"] = pd.DataFrame(df.loc[:, \"specializations\"]).applymap(_process_specs)\n",
        "  for i in range(1, 30):\n",
        "    df[str(i)] = 0\n",
        "  for index in indexes:\n",
        "    for spec in df.loc[index, \"specializations\"]:\n",
        "      df.loc[index, str(spec)] = 1\n",
        "  df = df.drop(\"specializations\", axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNuA0HIsH14c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_specification_features(df):\n",
        "  df[\"first_spec\"] = 0\n",
        "  df[\"second_spec\"] = 0\n",
        "  for index, row in tqdm(df.iterrows()):\n",
        "      df.loc[index, [\"first_spec\", \"second_spec\"]] = spec_modif(row[\"specializations\"])\n",
        "  df[\"spec_split\"] = df[\"specializations\"].apply(lambda x: \" \".join(str(x).split('.')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_sM_ChplFDX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "66f0ab4b-3cda-4639-ed97-f34cb27a5661"
      },
      "source": [
        "# или выделяем все специализации\n",
        "'''\n",
        "indexes = data_vacs_clean.index\n",
        "\n",
        "def spec_modif(elem):\n",
        "  specs = set()\n",
        "  for spec in elem.split():\n",
        "    specs.add(int(spec.split('.')[0]))\n",
        "  return specs\n",
        "\n",
        "data_vacs_clean.loc[:, \"specializations\"] = pd.DataFrame(data_vacs_clean.loc[:, \"specializations\"]).applymap(spec_modif)\n",
        "\n",
        "for i in range(1, 30):\n",
        "  data_vacs_clean[str(i)] = 0\n",
        "for index in indexes:\n",
        "  for spec in data_vacs_clean.loc[index, \"specializations\"]:\n",
        "    data_vacs_clean.loc[index, str(spec)] = 1\n",
        "\n",
        "data_vacs_clean = data_vacs_clean.drop(\"specializations\", axis=1)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'\\nindexes = data_vacs_clean.index\\n\\ndef spec_modif(elem):\\n  specs = set()\\n  for spec in elem.split():\\n    specs.add(int(spec.split(\\'.\\')[0]))\\n  return specs\\n\\ndata_vacs_clean.loc[:, \"specializations\"] = pd.DataFrame(data_vacs_clean.loc[:, \"specializations\"]).applymap(spec_modif)\\n\\nfor i in range(1, 30):\\n  data_vacs_clean[str(i)] = 0\\nfor index in indexes:\\n  for spec in data_vacs_clean.loc[index, \"specializations\"]:\\n    data_vacs_clean.loc[index, str(spec)] = 1\\n\\ndata_vacs_clean = data_vacs_clean.drop(\"specializations\", axis=1)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFome8N-xr5w",
        "colab_type": "text"
      },
      "source": [
        "# Доп. обработка данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiagQG6hJsJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def spec_modif_ten(df):  # df was from vacs_train_clean_adv.csv. Load it?\n",
        "  df_new = df.copy()\n",
        "  # new columns for specializations\n",
        "  for i in range(10):\n",
        "    df_new['spec' + str(i) + '**'] = 0\n",
        "  \n",
        "  # fill these columns\n",
        "  for index, row in (df_new.iterrows()):\n",
        "    spec_lst = list(row.specializations.split())\n",
        "    for spec in spec_lst:\n",
        "      spec_num = int(spec.split('.')[1])\n",
        "      df_new.loc[index, 'spec' + str(spec_num // 100) + '**'] = spec_num\n",
        "  \n",
        "  # fill empty cities\n",
        "  df_new = df_new.fillna('unknown')\n",
        "  return df_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj6AdShJZQf8",
        "colab_type": "text"
      },
      "source": [
        "# Добавление координаты городов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcIjS8dkKrOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_city_coord_feature(df): # this is the crapiest function i've ever seen\n",
        "  df_city = df.copy()\n",
        "  df_city['city'].fillna(value='Cанкт-Петербург', inplace=True)\n",
        "  df_city.loc[df_city['city'] == 'unknown', 'city'] ='Cанкт-Петербург' \n",
        "  if df_city is None:\n",
        "    raise AssertionError\n",
        "  geolocator = Nominatim()\n",
        "  geocode = RateLimiter(geolocator.geocode, min_delay_seconds= 0.1)\n",
        "  def get_adress(adr):\n",
        "    loc = geocode(adr)\n",
        "    if loc is not None:\n",
        "      return ','.join(map(str, [loc.latitude, loc.longitude]))\n",
        "    else:\n",
        "      return '59.9606739,30.1586551'\n",
        "\n",
        "  uniq_city = pd.Series(df_city['city'].unique())\n",
        "  location = uniq_city.apply(get_adress)\n",
        "\n",
        "  mask = pd.Series(location.to_list(),index=uniq_city)\n",
        "  coord_city = df_city['city'].apply(lambda x: mask[x]).str.split(',',expand=True)\n",
        "  df_city['coord_lat'] = pd.to_numeric(coord_city[0])\n",
        "  df_city['coord_lon'] = pd.to_numeric(coord_city[1])\n",
        "  return df_city"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY1yycqCivEU",
        "colab_type": "text"
      },
      "source": [
        "# Предсказание среднего\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOARxSML4MmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_predict(regressor, X_train, X_test, y_train, y_test):\n",
        "  # regressor.fit(X_train, y_train)\n",
        "  y_pred = regressor.predict(X_test)\n",
        "  print_metrics(y_test, y_pred)\n",
        "  # show_error_hist(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgNMzoq_nUmQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "def save_model_pickle(model, name, path='/content/drive/My Drive/Hacaton/Models_Pickled/'):\n",
        "  pickle.dump(model, open(path + name, 'wb'))\n",
        "\n",
        "\n",
        "def save_model_catboost(model, name, path='/content/drive/My Drive/Hacaton/Models_Pickled/'):\n",
        "  model.save_model(path+name, format=\"cbm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZtIMzvtWh92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_split(df):\n",
        "  \"\"\"\n",
        "  return dataframe for X, values for y\n",
        "  \"\"\" \n",
        "  X = df.drop(columns=[\"salary_from\"])\n",
        "  y = df.loc[:, [\"salary_from\"]]\n",
        "  TMP = train_test_split(X, y, test_size=0.3, random_state=17)\n",
        "  return TMP[0], TMP[1], TMP[2].values, TMP[3].values\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj9VCtD6X_U0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_metrics(y_test, y_pred):\n",
        "  print(\"MAE =\", int(mean_absolute_error(y_test, y_pred)))\n",
        "  print(\"MSE =\", int(mean_squared_error(y_test, y_pred)))\n",
        "  print(\"R2 =\", r2_score(y_test, y_pred).round(3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQoFlUHRYPjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_error_hist(y_test, y_pred):\n",
        "  print(y_test.shape)\n",
        "  print(y_pred.shape)\n",
        "  result_df_stupid = pd.DataFrame(np.concatenate((y_test, y_pred, y_test - y_pred), axis=1),\n",
        "                         columns=[\"y_test\", \"y_pred\", \"error\"])\n",
        "  plt.rcParams['figure.figsize'] = [12, 6]\n",
        "  result_df_stupid.error.hist(bins=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCGqIRWnWJni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def avarage_predict(X_train, X_test, y_train, y_test):\n",
        "  if df is None:\n",
        "    df = load_dataset('vacs_city.csv')\n",
        "  y_pred = np.array([y.mean()] * len(y_test))\n",
        "  print_metrics(y_test, y_pred)\n",
        "  show_error_hist(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soyVEd6U-08i",
        "colab_type": "text"
      },
      "source": [
        "# Линейная регрессия"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVs4lH9AZviY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot_split(df):\n",
        "  X = df.drop(columns=[\"salary_from\", \"name.lemm\", \"description.lemm\", \"city\", \"specializations\"])\n",
        "  y = df.loc[:, [\"salary_from\"]]\n",
        "  X_one_hot = pd.get_dummies(X)\n",
        "  TMP = train_test_split(X_one_hot, y, test_size=0.3, random_state=17)\n",
        "  return TMP[0].values, TMP[1].values, TMP[2].values, TMP[3].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qx7aJkvyYx5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_predict(df):\n",
        "  if df is None:\n",
        "    df = load_dataset('vacs_city.csv')\n",
        "\n",
        "  X_train, X_test, y_train, y_test = one_hot_split(df)\n",
        "\n",
        "  LinReg = LinearRegression()\n",
        "  LinReg.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = LinReg.predict(X_test)\n",
        "\n",
        "  print_metrics(y_test, y_pred)\n",
        "  show_error_hist(y_test, y_pred)\n",
        "  print_feature_importances(regressor)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndgx9Gi4NSfC",
        "colab_type": "text"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49MNhKSDZc9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "def svm_predict(df):\n",
        "  if df is None:\n",
        "    df = load_dataset('vacs_city.csv')\n",
        "\n",
        "  X_train, X_test, y_train, y_test = one_hot_split(df)\n",
        "\n",
        "  svm_clf = make_pipeline(StandardScaler(), SVR(kernel='rbf', C=1e3, gamma=0.1, cache_size=2000))\n",
        "\n",
        "  svm_clf.fit(X_train[:10000], y_train[:10000])  # cause svm sucks anyway\n",
        "\n",
        "  y_pred = svm_clf.predict(X_test)\n",
        "\n",
        "  print_metrics(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-3zvr1EDsKw",
        "colab_type": "text"
      },
      "source": [
        "# CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rpQk9WmyH27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7bO27L5e8pG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_feature_importances(clf):\n",
        "  for name, imp in zip(X.head(0), clf.feature_importances_):\n",
        "    print(str(name) + \" : \" + str(imp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ6diTkpa548",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def catboost_predict(X_train, X_test, y_train, y_test, iterations=1000):\n",
        "  catboost = CatBoostRegressor(iterations=iterations, random_seed=17)\n",
        "  catboost.fit(X_train, y_train, cat_features=list(range(X_train.shape[1] - 4)), plot=True)\n",
        "  save_model_catboost(catboost, 'catboost.cbm')\n",
        "  print(\"catboost fitted\")\n",
        "  model_predict(catboost, X_train, X_test, y_train, y_test)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3KjiIdB0Z2p",
        "colab_type": "text"
      },
      "source": [
        "# Повышаем Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuG2K_eKfoCX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_len_feature(df=None):\n",
        "  if df is None:\n",
        "    df = load_dataset('vacs_city.csv')\n",
        "  df_len = df.copy()\n",
        "  df_len[\"description_len\"] = df_len[\"description.lemm\"].apply(len)\n",
        "  return df_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6a08AFAX36-",
        "colab_type": "text"
      },
      "source": [
        "# TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycyw7YJnCV2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tf_idf_predictions(df_train, df_test, y_train, y_test, iterations=10):\n",
        "  vectorizer_1 = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, max_features=30000)\n",
        "  X_train_text_1 = vectorizer_1.fit_transform(df_train.loc[:, \"description.lemm\"])\n",
        "  save_model_pickle(vectorizer_1, 'vectorizer_1.pkl')\n",
        "  X_test_text_1 = vectorizer_1.transform(df_test.loc[:, \"description.lemm\"])\n",
        "  \n",
        "  vectorizer_2 = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, max_features=15000)\n",
        "  X_train_text_2 = vectorizer_2.fit_transform(df_train.loc[:, \"name.lemm\"])\n",
        "  save_model_pickle(vectorizer_2, 'vectorizer_2.pkl')\n",
        "  X_test_text_2 = vectorizer_2.transform(df_test.loc[:, \"name.lemm\"])\n",
        "\n",
        "  vectorizer_3 = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, max_features=15000)\n",
        "  X_train_text_3 = vectorizer_3.fit_transform(df_train.loc[:, \"city\"])\n",
        "  save_model_pickle(vectorizer_3, 'vectorizer_3.pkl')\n",
        "  X_test_text_3 = vectorizer_3.transform(df_test.loc[:, \"city\"])\n",
        "\n",
        "  vectorizer_4 = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, max_features=15000)\n",
        "  X_train_text_4 = vectorizer_4.fit_transform(df_train.loc[:, \"company\"])\n",
        "  save_model_pickle(vectorizer_4, 'vectorizer_4.pkl')\n",
        "  X_test_text_4 = vectorizer_4.transform(df_test.loc[:, \"company\"])\n",
        "\n",
        "  vectorizer_5 = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, max_features=15000)\n",
        "  X_train_text_5 = vectorizer_5.fit_transform(df_train.loc[:, \"key_skills\"])\n",
        "  save_model_pickle(vectorizer_5, 'vectorizer_5.pkl')\n",
        "  X_test_text_5 = vectorizer_5.transform(df_test.loc[:, \"key_skills\"])\n",
        "\n",
        "  vectorizer_6 = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, max_features=15000)\n",
        "  X_train_text_6 = vectorizer_6.fit_transform(df_train.loc[:, \"specializations.names\"])\n",
        "  save_model_pickle(vectorizer_6, 'vectorizer_6.pkl')\n",
        "  X_test_text_6 = vectorizer_6.transform(df_test.loc[:, \"specializations.names\"])\n",
        "\n",
        "  X_train_full = scipy.sparse.hstack([X_train_text_1, X_train_text_2, X_train_text_3,\n",
        "                                      X_train_text_4, X_train_text_5, X_train_text_6]).tocsr()\n",
        "  X_test_full = scipy.sparse.hstack([X_test_text_1, X_test_text_2, X_test_text_3,\n",
        "                                  X_test_text_4, X_test_text_5, X_test_text_6]).tocsr()\n",
        "\n",
        "  # possibly safe/load model here\n",
        "  # CatBoost = CatBoostRegressor(iterations=iterations, random_seed=17, task_type='GPU') # rewrite to model.predict\n",
        "  # CatBoost.fit(X_train_full, y_train, plot=True)\n",
        "\n",
        "  # save_model_catboost(CatBoost, 'Tf-IdfCatNotFull.cbm')\n",
        "\n",
        "  print(X_train_full.shape)\n",
        "\n",
        "  y_pred_tf_idf = CatBoost.predict(X_test_full)\n",
        "  y_pred_tf_idf_on_train = CatBoost.predict(X_train_full)\n",
        "  print_metrics(y_test, y_pred_tf_idf)\n",
        "\n",
        "  return y_pred_tf_idf_on_train, y_pred_tf_idf\n",
        "  # eli5.show_weights(estimator=CatBoost,\n",
        "  #                 feature_names=(list(vectorizer.get_feature_names())),\n",
        "  #                 top=50)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aEFn2LruwOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tf_idf_as_feature(X_train, X_test, y_train, y_test, iterations=100):\n",
        "\n",
        "  y_pred_tf_idf_on_train, y_pred_tf_idf_on_test = tf_idf_predictions(X_train, X_test, y_train, y_test, iterations=iterations)  # !!! change iterations\n",
        "\n",
        "  y_pred_tf_idf_on_test = y_pred_tf_idf_on_test.reshape((len(y_pred_tf_idf_on_test), 1))\n",
        "  y_pred_tf_idf_on_train = y_pred_tf_idf_on_train.reshape((len(y_pred_tf_idf_on_train), 1))\n",
        "\n",
        "  X_test_with_tf_idf = np.concatenate([X_test, y_pred_tf_idf_on_test], axis=1)\n",
        "  X_train_with_tf_idf = np.concatenate([X_train, y_pred_tf_idf_on_train], axis=1)\n",
        "  return X_train_with_tf_idf, X_test_with_tf_idf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Hu5q1z1P8Sq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRI4xck_wgN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hp7LgVPpoaPD",
        "colab_type": "text"
      },
      "source": [
        "# main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Za1kjwKHoiOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "initial_df = load_dataset('vacs_train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaBF-zW_pK5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned_df = clean_data(initial_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzEI_tdgpQA9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8557a380-2ddc-406e-9acc-d0c51c3a2e82"
      },
      "source": [
        "add_specification_features(cleaned_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100001it [03:28, 480.34it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Lby-_75quYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned_df = spec_modif_ten(cleaned_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoKMMVRdqFBK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "71adae36-e192-456d-dc5a-9b7fbdd1b24f"
      },
      "source": [
        "cleaned_df = add_city_coord_feature(cleaned_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/geopy/geocoders/osm.py:143: UserWarning: Using Nominatim with the default \"geopy/1.17.0\" `user_agent` is strongly discouraged, as it violates Nominatim's ToS https://operations.osmfoundation.org/policies/nominatim/ and may possibly cause 403 and 429 HTTP errors. Please specify a custom `user_agent` with `Nominatim(user_agent=\"my-application\")` or by overriding the default `user_agent`: `geopy.geocoders.options.default_user_agent = \"my-application\"`. In geopy 2.0 this will become an exception.\n",
            "  UserWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8dnGi_dqPr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned_df = add_len_feature(cleaned_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itFq1sA7qkst",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "026760fd-376a-4981-b869-1d88d6a42da0"
      },
      "source": [
        "cleaned_df.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name.lemm</th>\n",
              "      <th>city</th>\n",
              "      <th>company.id</th>\n",
              "      <th>salary_from</th>\n",
              "      <th>employment</th>\n",
              "      <th>schedule</th>\n",
              "      <th>experience</th>\n",
              "      <th>key_skills</th>\n",
              "      <th>specializations</th>\n",
              "      <th>description.lemm</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "      <th>first_spec</th>\n",
              "      <th>second_spec</th>\n",
              "      <th>spec0**</th>\n",
              "      <th>spec1**</th>\n",
              "      <th>spec2**</th>\n",
              "      <th>spec3**</th>\n",
              "      <th>spec4**</th>\n",
              "      <th>spec5**</th>\n",
              "      <th>spec6**</th>\n",
              "      <th>spec7**</th>\n",
              "      <th>spec8**</th>\n",
              "      <th>spec9**</th>\n",
              "      <th>coord_lat</th>\n",
              "      <th>coord_lon</th>\n",
              "      <th>description_len</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>менеджер туризм</td>\n",
              "      <td>Санкт-Петербург</td>\n",
              "      <td>605490</td>\n",
              "      <td>40000.0</td>\n",
              "      <td>full</td>\n",
              "      <td>fullDay</td>\n",
              "      <td>between1And3</td>\n",
              "      <td>0</td>\n",
              "      <td>17.334 17.242 17.149 22.223 22.39 22.199</td>\n",
              "      <td>обязанность работа турист физический юридическ...</td>\n",
              "      <td>2016</td>\n",
              "      <td>8</td>\n",
              "      <td>21</td>\n",
              "      <td>14</td>\n",
              "      <td>17</td>\n",
              "      <td>22</td>\n",
              "      <td>39</td>\n",
              "      <td>199</td>\n",
              "      <td>223</td>\n",
              "      <td>334</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>59.960674</td>\n",
              "      <td>30.158655</td>\n",
              "      <td>818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>помощник руководитель</td>\n",
              "      <td>Cанкт-Петербург</td>\n",
              "      <td>605490</td>\n",
              "      <td>40000.0</td>\n",
              "      <td>full</td>\n",
              "      <td>fullDay</td>\n",
              "      <td>between1And3</td>\n",
              "      <td>0</td>\n",
              "      <td>4.205 4.429 6.319 6.247 2.249</td>\n",
              "      <td>вакансия открывать рамка отдел строительный от...</td>\n",
              "      <td>2016</td>\n",
              "      <td>8</td>\n",
              "      <td>21</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>249</td>\n",
              "      <td>319</td>\n",
              "      <td>429</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>59.930287</td>\n",
              "      <td>30.367073</td>\n",
              "      <td>374</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   name.lemm             city  ...  coord_lon  description_len\n",
              "index                                          ...                            \n",
              "0            менеджер туризм  Санкт-Петербург  ...  30.158655              818\n",
              "1      помощник руководитель  Cанкт-Петербург  ...  30.367073              374\n",
              "\n",
              "[2 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcdPjWHnzT-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_df = add_len_feature(load_dataset('vacs_clean_adv.csv'))  # cleaned_df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHIxkEZP2l9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train, df_test, y_train, y_test = custom_split(final_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtwDvLEcG_hi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "18bc1939-e018-4b24-feb4-c62c2e2ea708"
      },
      "source": [
        "df_train.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name.lemm</th>\n",
              "      <th>city</th>\n",
              "      <th>company.id</th>\n",
              "      <th>company</th>\n",
              "      <th>employment</th>\n",
              "      <th>schedule</th>\n",
              "      <th>experience</th>\n",
              "      <th>key_skills</th>\n",
              "      <th>specializations</th>\n",
              "      <th>specializations.names</th>\n",
              "      <th>description.lemm</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "      <th>first_spec</th>\n",
              "      <th>second_spec</th>\n",
              "      <th>spec_split</th>\n",
              "      <th>coord_lat</th>\n",
              "      <th>coord_lon</th>\n",
              "      <th>description_len</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37779</th>\n",
              "      <td>специалист работа акт оказание услуга документ</td>\n",
              "      <td>Cанкт-Петербург</td>\n",
              "      <td>490</td>\n",
              "      <td>Ренессанс cтрахование, Группа</td>\n",
              "      <td>full</td>\n",
              "      <td>fullDay</td>\n",
              "      <td>noExperience</td>\n",
              "      <td>пусто</td>\n",
              "      <td>4.429 4.181 5.51 15.388 15.281 19.170</td>\n",
              "      <td>Административный персонал - Делопроизводство |...</td>\n",
              "      <td>ренессанс страхование предлагать специалист ка...</td>\n",
              "      <td>2016</td>\n",
              "      <td>8</td>\n",
              "      <td>19</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>4 429 4 181 5 51 15 388 15 281 19 170</td>\n",
              "      <td>59930</td>\n",
              "      <td>30367</td>\n",
              "      <td>1580</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            name.lemm  ... description_len\n",
              "index                                                  ...                \n",
              "37779  специалист работа акт оказание услуга документ  ...            1580\n",
              "\n",
              "[1 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzJdtqX83n9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test = tf_idf_as_feature(df_train, df_test, y_train, y_test, iterations=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8VI8jqEKSH-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "053775f5-d6ff-4217-da4f-32aba8e509a8"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 22)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaaTsWDF3v2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "catboost_predict(X_train, X_test, y_train, y_test, iterations=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF_82lxO3-XE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrOGwRZH_9HN",
        "colab_type": "text"
      },
      "source": [
        "# Предсказание тестовых"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKxzp9DEAFH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}